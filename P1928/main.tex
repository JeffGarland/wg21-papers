\newcommand\wgTitle{Merge data-parallel types from the Parallelism TS 2}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{D1928R2}
\newcommand\wgGroup{SG1, LEWG}
\newcommand\wgTarget{\CC{}26}
%\newcommand\wgAcknowledgements{ }

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{comment}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{simd#1}\xspace}
\newcommand\simdT{\type{simd<T>}\xspace}
\newcommand\valuetype{\type{value\_type}\xspace}
\newcommand\referencetype{\type{reference}\xspace}
\newcommand\whereexpression{\type{where\_expression}\xspace}
\newcommand\simdcast{\code{simd\_cast}\xspace}
\newcommand\mask[1][]{\type{simd\_mask#1}\xspace}
\newcommand\maskT{\type{simd\_mask<T>}\xspace}
\newcommand\fixedsizeN{\type{simd\_abi::fixed\_size<N>}\xspace}
\newcommand\fixedsizescoped{\type{simd\_abi::fixed\_size}\xspace}
\newcommand\fixedsize{\type{fixed\_size}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}
\DeclareRobustCommand\simdabi{\code{simd\_abi\MayBreak::\MayBreak}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  After the Parallelism TS 2 was published in 2018, data-parallel types
  (\simdT) have been implemented and used.
  Now there is sufficient feedback to improve and merge Section 9 of the
  Parallelism TS 2 into the IS working draft.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
%\input{strawpolls}

\section{Introduction}
\cite{P0214R9} introduced \simdT and related types and functions into the Parallelism TS 2 Section 9.
The TS was published in 2018.
An incomplete and non-conforming (because P0214 evolved) implementation existed for the whole time P0214 progressed through the committee.
Shortly after the GCC 9 release, a complete implementation of Section 9 of the TS was made available.
Since GCC 11 a complete \code{simd} implementation of the TS is part of its standard library.

Note: The first revision of this paper did not propose a merge.
In the meantime the TS feedback progressed to a point where a merge should happen ASAP.

\subsection{Related papers}
\begin{description}
  \item[\wglink{P0350}] Before publication of the TS, SG1 approved \cite{P0350R0} which did not progress in time in LEWG to make it into the TS.
    \wglink{P0350} is moving forward independently.

  \item[\wglink{P0918}] After publication of the TS, SG1 approved \cite{P0918R2} which adds \code{shuffle}, \code{interleave}, \code{sum_to}, \code{multiply_sum_to}, and \code{saturated_simd_cast}.
    \wglink{P0918} will move forward independently.

  \item[\wglink{P1068}] R3 of the paper removed discussion/proposal of a \code{simd} based API because it was targeting \CC{}23 with the understanding of \code{simd} not being ready for \CC{}23.
    This is unfortunate as the presence of \code{simd} in the IS might lead to a considerably different assessment of the iterator/range-based API proposed in P1068.

  \item[\wglink{P0917}] The ability to write code that is generic wrt. arithmetic types and \code{simd} types is considered to be of high value (TS feedback).
    Conditional expressions via the \code{where} function were not all too well received.
    Conditional expressions via the conditional operator would provide a solution deemed perfect by those giving feedback (myself included).

  \item[draft on non-member {operator[]}] TODO

  \item[\wglink{P2600}] The fix for ADL is important to ensure the above two papers do not break existing code.

  \item[\wglink{P0543}] The paper proposing functions for saturation arithmetic expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P0553}] The bit operations that are part of \CC{}20 expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P2638}] Intel’s response to \wglink{P1915R0} for \code{std::simd}

  \item[\wglink{P2663}] \code{std::simd<std::complex<T>>}.

  \item[\wglink{P2664}] Permutations for \code{simd}.

\end{description}
The papers \wglink{P0350}, \wglink{P0918}, \wglink{P2663}, \wglink{P2664}, and
the \code{simd}-based \wglink{P1068} fork currently have no shipping vehicle
and are basically blocked on this paper.

\section{Changes after TS feedback}\label{sec:changes}
\cite{P1915R0} (Expected Feedback from \code{simd} in the Parallelism TS 2) was published in 2019, asking for feedback to the TS.
I received feedback on the TS via the GitHub issue tracker, e-mails, and personal conversations.
There is also a lot of valuable feedback published in \wglink{P2638} ``Intel’s response to \wglink{P1915R0} for \code{std::simd}''.
This paper captures the major change requests but should still be considered a work-in-progress.

\subsection{improve ABI tags}
I received consistent feedback that \simdabi\code{compatible<T>} is the wrong default and it should rather be \simdabi\code{native<T>} instead.
All my tutorial material instructed users to use \stdx\code{native_simd<T>}.
There really is little use for \simdabi\code{compatible<T>}.
The preferred approach should be the use of \simdabi\code{native<T>} together with compiler flags that limit the available registers and instructions to whatever the user deems “compatible”.
Consequently, there is no reason to keep \simdabi\code{compatible<T>} in its current form.

Another common question was about a “fixed size” ABI tag, similar to \stdx\simdabi\code{fixed_size<N>} but without the ABI compatibility cost.%
\footnote{Implementations of the TS are encouraged to make passing \code{fixed_size} objects ABI compatible between different hardware generations and/or even different architectures.}
Basically, the ABI footgun should be as dangerous as \stdx\simdabi\code{native<T>}.
The answer to that FAQ is to use \stdx\simdabi\code{deduce_t<T, N>} as ABI tag.
This will provide you with a high-performance footgun, if supported, but might also fall back to \stdx\simdabi\code{fixed_size<N>}.
With \stdx\simdabi\code{deduce_t<T, N>} turning out to be used potentially more often than \stdx\simdabi\code{fixed_size<N>} the aliases and names should be revisited.
My proposal:

\begin{description}
  \item[\code{A0 = \simdabi native<T>}] \emph{(no change from the TS semantics)}\\
    \code{simd<T, A0>} abstracts a SIMD register (or similar) with highest performance on the target system (typically widest available register, but that's a QoI choice).
    Consequently, the number of elements is chosen by the implementation and may differ for different \code{T} and different compiler flags.
    \simdabi\code{native<T>} is an alias for an unspecified type.
    \simdabi\code{native<T>} can be an alias for \simdabi\code{scalar}.
    If \code{sizeof(simd<T, A0>)} or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1 differ from the same expressions in TU2, then the types \code{A0} in TU1 and TU2 have a different name.

  \item[\code{A1 = \simdabi fixed_size<T, N>}] \emph{(different to the TS semantics)}\\
    \code{simd<T, A1>} abstracts one or more registers storing \code{N} values.
    The actual hardware resources might store more values; but instructions are generated to make it appear as if there are exactly \code{N} values stored and manipulated.

    Parameter passing may be ABI incompatible between different TUs when compiled with different compiler flags.
    Therefore, if \code{sizeof(simd<T, A0>)}%
    \footnote{\code{A0} is not a typo; this depends on \simdabi\code{native<T>}}
    or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1
    differ from the same expressions in TU2, then the types \code{A1} in TU1
    and TU2 have a different name.
    This new requirement (wrt. the TS) is the reason for the additional
    \code{T} parameter.
    This allows an implementation to define the \code{fixed_size} alias as e.g.
    \lstinline@template <typename T, @
    \lstinline@int N> @
    \lstinline@using fixed_size @
    \lstinline@= _Fixed<N, native<T>>;@.
    \code{A1} and \code{A0} are always different types, i.e. even if \code{simd_size_v<T, A0> == N}.

    A major difference to \stdx\simdabi\code{fixed_size<N>} in the TS is about \code{simd_mask}.
    In order to support ABI stability the \code{simd_mask} implementation must choose one form of storage for all possible targets:
    \begin{itemize}
      \item full SIMD registers with all bits set to 1 or 0 per corresponding element
      \item bitmasks
      \item an array of \code{bool} or similar
    \end{itemize}
    The new intent for the \code{fixed_size<T, N>} ABI tag would be to allow \code{simd_mask<T, A1>} to use either choice depending only on compiler flags.

  \item[\code{A2 = \simdabi abi_stable<N>}] \emph{(new, but same semantics as \code{fixed_size} in the TS)}\\
    \code{simd<T, A2>} abstracts the same hardware resources as \code{simd<T, A1>}, however with the intent of ABI compatibility between differently compiled TUs.
    This can't be a normative requirement; and thus \code{A2} and \code{A1} may be equivalent types (QoI).
    (Note: There is no use for a \simdabi\code{abi_stable<T>} type since the parameter passing differences are tied to the number of elements in a SIMD vector.
    Thus, either \simdabi\code{native<T>} would work just fine or \simdabi\code{abi_stable<T>} would lead to incompatibilities, because types with the same name had different \code{sizeof} and \code{alignof}.)

  \item[\code{A3 = \simdabi scalar}]\ \\
    No change.
\end{description}

At this point the \simdabi\code{deduce} facility seems to be obsolete.
However, it is still a useful tool for implementing the \code{rebind_simd} and \code{resize_simd} traits.
Without more compelling reason for removal, it should be merged as is.
%In theory, its ability to take an optional pack of ABI tags into account for its decision would be lost when removing \simdabi\code{deduce}.
%However, I have not heard of any users who want to use this feature.
%My recommendation is removal.%
%\footnote{For reference: my implementation simply ignores the pack of ABI tags given to \simdabi\code{deduce}.}

\subsubsection{Naming discussion}

For context on naming, consider the use-cases that the ABI tags serve:

\begin{description}
  \item[\simdabi\code{native<T>}] The equivalent to \code{T}: a direct abstraction of available hardware resources in terms of registers and instructions.

  \item[\simdabi\code{fixed_size<T, N>}] Higher abstraction level than \code{native<T>}: the user/algorithm dictates the number of elements to be processed in parallel.
    The objects might not be direct mappings to hardware resources, but they use the best that is available on the given target system.

  \item[\simdabi\code{abi_stable<N>}] The type to use as function parameter type on ABI boundaries.
    This type allows TUs translated with different machine-related compiler flags to interact correctly.

  \item[\simdabi\code{scalar}] The actual type of \code{native<T>} if the target hardware has no support for parallel processing of elements of \code{T}.%
    \footnote{A typical example is \simdabi\code{native<long double>}.}
    In addition, \code{simd<T, simd_abi::scalar>} can be a useful debugging tool.
\end{description}

For reference, the above names are my preference over the following alternatives.
\begin{itemize}
  \item alternatives for \code{fixed_size}:
    \begin{itemize}
      \item \code{simd_abi::fixed_native<N>} with \code{simd} alias \code{fixed_native_simd<T, N>}
      \item \code{simd_abi::fixed<N>} with \code{simd} alias \code{fixed_simd<T, N>}
      \item \code{simd_abi::sized<N>} with \code{simd} alias \code{sized_simd<T, N>}
    \end{itemize}

  \item alternatives for \code{abi_stable}:
    \begin{itemize}
      \item \code{simd_abi::fixed_compatible<N>} with \code{simd} alias \code{fixed_compatible_simd<T, N>}
      \item \code{simd_abi::compatible<N>} with \code{simd} alias \code{compatible_simd<T, N>}
      \item \code{simd_abi::abi_compatible<N>} with \code{simd} alias \code{abi_compatible_simd<T, N>}
      \item \code{simd_abi::parameter<N>} with \code{simd} alias \code{parameter_simd<T, N>} or \code{simd_parameter<T, N>}
    \end{itemize}
\end{itemize}

\subsubsection{Alternative: no ABI boundary helper}

See \sect{sec:noabihelper}.

\subsection{Simplify/generalize casts}\label{sec:casts}

The change to the ABI tags requires a reconsideration of cast functions and
implicit and explicit casts between data-parallel types of different ABI tags.
This is in addition to TS feedback on casts being to strict or cumbersome to use.

\subsubsection{Interconvertible \code{fixed_size} and \code{abi_stable}}

Conversions between \code{fixed_size_simd<T, N>} and \code{abi_stable_simd<T,
N>} should be implicit, because the only difference is in how the parameter is
passed to a function.
Thus, a function on an API boundary might want to declare function arguments
with \code{abi_stable<N>} and then continue with \code{fixed_size<T, N>} in its
implementation.
However, conversions between \code{fixed_size_simd_mask<T, N>} and
\code{abi_stable_simd_mask<T, N>} might require costly conversion between
different mask representations.
It would certainly be inconsistent to allow implicit conversions for
\code{simd} but not \code{simd_mask}.
Also this potential mask conversion cost exists for today's
\stdx\simdabi\code{fixed_size_simd_mask<T, N>} for every mask operation, so
reducing it to implicit conversions on ABI boundaries would already be a huge
improvement.

\subsubsection{More (explicit) converting constructors}

The TS allows implicit casts between \code{fixed_size<N>} types that only
differ in element type and where the values are preserved (“every possible
value of \code{U} can be represented with type \code{value_type}”).

However, from experience with the TS, it is better to also enable implicit
conversions between any \code{simd} specializations with equal element count,
even if such a conversion might be non-portable between targets with different
native SIMD widths.
The expectation is, that users set up their types according to a pattern
similar to \lst{lst:simdtypespattern}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:simdtypespattern,caption={
  Recommended setup of \code{simd} types
}]
using  floatv = std::simd<float>;
using doublev = std::rebind_simd_t<double, floatv>;
using  int32v = std::rebind_simd_t<std:: int32_t, floatv>;
using uint32v = std::rebind_simd_t<std::uint32_t, floatv>;
using  int16v = std::rebind_simd_t<std:: int16_t, floatv>;
using uint16v = std::rebind_simd_t<std::uint16_t, floatv>;
// ...
\end{lstlisting}
Thus, users will work with a set of types that have equal number of elements by
construction.
Some of the types may use the \code{fixed_size} ABI tag and some may use an
extended ABI tag.
This detail should not stop the user from being able to cast between a
compiler-flag dependent subset of these types.

%There is no way to know how \code{N} of a given \code{fixed_size} ABI tag was
%determined, so we have to tailor the design for one assumption or the other.
%(If we expect most of our \code{simd} users to use CI for compiling their code
%for at least two different targets with different SIMD widths, then
%non-portable use of such implicit casts can be caught automatically before
%integration to the main branch.)

Besides a constraint on the number of elements being equal, the converting
constructor should be conditionally \code{explicit}:
Implicit casts are only allowed if the element type conversion is
value-preserving (same wording as in the TS).

This resolves major inconveniences when working with mixed-precision
operations (cf. \ttref{tt:better with conv ctors}).
\begin{tonytable}{Improved generic code after adding converting constructors}\label{tt:better with conv ctors}
  \begin{lstlisting}
namespace stdx = std::experimental;

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              stdx::is_simd_v<T>,
              stdx::rebind_simd_t<int, T>, int>;
  I c;
  if constexpr (stdx::is_simd_v<T>) {
    c = stdx::static_simd_cast<I>(a) + b;
  } else {
    c = static_cast<int>(a) + b;
  }
  g(c);
}
  \end{lstlisting}
  &
  \begin{lstlisting}
// assuming simd in namespace std

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              std::is_simd_v<T>,
              std::rebind_simd_t<int, T>, int>;
  I c = static_cast<I>(a) + b;





  g(c);
}
  \end{lstlisting}
\end{tonytable}%
Type conversions for \code{simd} are still less error-prone than builtin types,
because conversions that might lose information require an explicit cast.
Also, an unintended widening of the SIMD register size can happen but is not
completely invisible as shown in \lst{lst:mixedprecision}.

\begin{lstlisting}[numbers=left,float={hbtp},label=lst:mixedprecision,caption={
  Mixed precision code using the types from \lst{lst:simdtypespattern}, ensuring equal element count
}]
void f(int32v a, doublev b, floatv c)
{
  doublev x = a * b + c; // OK: implicit (value-preserving) conversion from int and float
    // to double. Requires twice the register space, but there's no way around it and the
    // result type requires it anyway.
  int32v y = a * b; // ERROR: implicit conversion from double to int not value-preserving
  int32v z1 = static_cast<int32v>(a * b); // OK: cast hints at implicit register widening
  int32v z2 = a * static_cast<int32v>(b); // OK
}
\end{lstlisting}

\subsubsection{Remove named cast functions}

From the cast functions \stdx\code{to_fixed_size}, \stdx\code{to_native}, and
\stdx\code{to_compatible} only the conversions from \simdabi\code{fixed_size<T,
N>} to \simdabi\code{native<T>} and back may still benefit from a named cast
function.
Most importantly, the conversion from \code{native} to its \code{fixed_size}
counterpart benefits from a cast expression that does not require spelling out
the destination type.
If only (explicit) converting constructors were provided by the standard
library, it would be simple enough for users to define their own
\code{to_fixed_size} function if they want one (e.g.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:userdefined-to-fixed-size,caption={
  Example of a user-defined \code{to_fixed_size} implementation if explicit casts are provided
}]
template <typename T>
constexpr auto to_fixed_size(std::simd<T> x)
{
  using R = std::fixed_size_simd<T, std::simd<T>::size()>;
  return static_cast<R>(x);
}
\end{lstlisting}
\lst{lst:userdefined-to-fixed-size}).
The reverse cast can trivially be spelled out as \code{static_cast<simd<T>>(y)}
in program code.
The only motivation for adding a \code{to_native} function would be the
provision of a counterpart for the \code{to_fixed_size} cast function.

If there is consensus to allow implicit conversions, then I believe the named
cast functions should be removed altogether.

\subsubsection{Remove \code{simd_cast} and \code{static_simd_cast}}
There are two cast function templates in the TS: \code{simd_cast} and
\code{static_simd_cast}.
The former is equivalent to the latter except that only value-preserving
conversions are allowed.
The template parameter can either be a \code{simd} specialization or a
vectorizable type \code{T}.
In the latter case, the cast function determines the return type as
\code{fixed_size_simd<T, input.size()>}.

If we allow all conversions covered by \stdx\code{simd_cast} and
\stdx\code{static_simd_cast} via \std\code{simd} constructors, then the cast
functions can be removed altogether.
The lost feature (cast via element type) can be replaced using
\code{rebind_simd} as shown in \ttref{tt:tsvsp1928casts}.
\begin{tonytable}{Casting without specifying the target ABI tag}\label{tt:tsvsp1928casts}
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = stdx::static_simd_cast<double>(x);
  // ...
}
  \end{lstlisting}
  &
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = std::rebind_simd_t<double, V>(x);
  // ...
}
  \end{lstlisting}
\end{tonytable}%

\subsubsection{mask casts}
\code{simd_mask} casts should work when \code{simd} casts work.
I.e. if \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
then \code{simd_mask<T0, A0>} is implicitly convertible to \code{simd_mask<T1,
A1>}.
The reverse (if \code{simd_mask} is convertible then \code{simd} is
convertible) does not have to be true.
Specifically, the TS allows all \code{fixed_size<N>} mask to be
interconvertible, irrespective of the element type.
For the IS merge, the proposal is to make this more consistent with \code{simd}
while also preserving most of the convenience:
Allow implicit conversions if the \code{sizeof} the element types are equal,
otherwise the conversion must be explicit.

Conversions with different element count are not possible via a constructor
(consistent with \code{simd}).
This would require a different function, such as the \code{resize<N>(simd)}
function proposed by \textcite{P2638R0}.

\subsubsection{Summary of casts}

\begin{enumerate}
  \item \code{simd<T0, A0>} is convertible to \code{simd<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
    if, additionally, the conversion \code{T0} to \code{T1} is
    value-preserving.

  \item \code{simd_mask<T0, A0>} is convertible to \code{simd_mask<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd_mask<T0, A0>} is implicitly convertible to
    \code{simd_mask<T1, A1>} if, additionally, \item \code{sizeof(T0) ==
    sizeof(T1)}.

  \item \code{simd<T0, A0>} can be \code{bit_cast}ed to \code{simd<T1, A1>} if
    \code{sizeof(simd<T0, A0>) == sizeof(simd<T1, A1>)} and neither \code{A0}
    nor \code{A1} are specializations of \simdabi\code{abi_stable}.

  \item \code{simd_mask<T0, A0>} can be \code{bit_cast}ed to \code{simd_mask<T1, A1>} if
    \code{sizeof(simd_mask<T0, A0>) == sizeof(simd_mask<T1, A1>)} and neither
    \code{A0} nor \code{A1} are specializations of \simdabi\code{abi_stable}.
\end{enumerate}

\subsection{Add \code{simd_mask} generator constructor}
The \code{simd} generator constructor is very useful for initializing objects
from scalars in a portable (i.e. different \code{simd::size()}) fashion.
The need for a similar constructor for \code{simd_mask} is less frequent, but,
even if only for consistency, there should be one.
Besides consistency, it is also useful, of course.
Consider a predicate function that is given without \code{simd} interface (e.g. from a library).
How do you construct a \code{simd_mask} from it?
With a generator constructor it is easy:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  const simd_mask<T> k([&](auto i) { return p(x[i]); });
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
Without the generator constructor one has to write e.g.:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  simd_mask<T> k;
  for (size_t i = 0; i < simd<T>::size(); ++i) {
    k[i] = p(x[i]);
  }
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
The latter solution makes it hard to initialize the \code{simd_mask} as \code{const}, is more verbose, is harder to optimize, and cannot use the sequencing properties the generator constructor allows.

Therefore add:
\begin{wgText}
\begin{itemdecl}
template<class G> simd_mask(G&& gen) noexcept;
\end{itemdecl}
\end{wgText}

\subsection{Complete casts for \code{simd_mask}}
The \code{simd_cast} and \code{static_simd_cast} overloads for \code{simd_mask} were forgotten for the TS.
Without those casts (and no casts via constructors) mixing different arithmetic types is painful.
There is no motivation for forbidding casts on \code{simd_mask}.

However, since the proposed change for casts removes \code{simd_cast} and
\code{static_simd_cast}, the problem is already solved.

%Therefore add the following overloads:
%\begin{wgText}
%\begin{codeblock}
  %template<class T, class U, class Abi> @\seebelow@ simd_cast(const simd_mask<U, Abi>&) noexcept;
  %template<class T, class U, class Abi> @\seebelow@ static_simd_cast(const simd_mask<U, Abi>&) noexcept;
%\end{codeblock}
%\end{wgText}

\subsection{\code{element_reference} is overspecified}
\code{element_reference} is spelled out in a lot of detail.
It may be better to define its requirements in a table instead.

This change is not reflected in the wording, pending encouragement from WG21 (mostly LWG).

\subsection{Default load/store flags to \code{element_aligned}}

Consider:
\medskip\begin{lstlisting}[style=Vc,numbers=left]
std::simd<float> v(addr, std::vector_aligned); @\label{lstline:vector_aligned}@
v.copy_from(addr + 1, std::element_aligned); @\label{lstline:load element_aligned}@
v.copy_to(dest, std::element_aligned); @\label{lstline:store element_aligned}@
\end{lstlisting}
Line~\ref{lstline:vector_aligned} supplies an optimization hint to the load operation.
Line~\ref{lstline:load element_aligned} says what really?
“Please don't crash.
I know this is not a vector aligned access\footnote{Of course, vector aligned is equivalent to element aligned if \code{simd<float>::size() == 1}}.”
Line~\ref{lstline:store element_aligned} says:
“I don't know whether it's vector aligned or not.
Compiler, if you know more, please optimize, otherwise just don't make it crash.”
(To clarify, the difference between lines~\ref{lstline:load element_aligned} and~\ref{lstline:store element_aligned} is what line~\ref{lstline:vector_aligned} says about the alignment of \code{addr}.)
In both cases of \code{element_aligned} access, the developer requested a behavior we take as given in all other situations.
Why does the TS force to spell it out in this case?

Since \CC{}20, we also have another option:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(std::assume_aligned<std::memory_alignment_v<std::simd<float>>>(addr)); @\label{lstline:assume_aligned}@
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}
This seems to compose well, except that line \ref{lstline:assume_aligned} is rather long for a common pattern in this interface.
Also, this removes implementation freedom because the library cannot statically determine the alignment properties of the pointer.

Consequently, as a minimal improvement to the TS keep the load/store flags as
is, but default them to \code{element_aligned}.
I.e.:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(addr, std::vector_aligned);
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}

\subsection{\code{constexpr} everything}
The libstdc++ implementation implements the complete TS API as \code{constexpr} as an optional extension.
This is useful (e.g. for computing constants) and not a significant implementation burden.
Users (as well as \textcite{P2638R0}) have called for \code{constexpr}.
The merge consequently adds \code{constexpr} to all functions.

\subsection{Specify \code{simd::size} as \code{integral_constant}}
The TS specifies \code{simd::size} as a \code{static constexpr} function returning the number of elements of the \code{simd} specialization.
Instead of a function, this paper uses a static data member of type \code{std::integral_constant<std::size_t, N>}, which is both convertible to \code{std::size_t} and callable.
The upside of using a static data member is that it can be used as function parameter without conversion to integer and thus easily pass the size into a function as constant expression.
See \lst{lst:sizeparam} for an example.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:sizeparam,caption={
    Example: Pass \code{simd::size} as ``constant expression function argument''
}]
template <std::ranges::contiguous_range R, std::size_t Size>
std::span<const std::ranges::range_value_t<R>, Size>
auto subscript(const R& r, std::size_t first, std::integral_constant<std::size_t, Size>) {
  return std::span<const std::ranges::range_value_t<R>, Size>(
    std::ranges::data(r) + first, Size());
}

void g(std::vector<float> data) {
  std::simd<float> v;
  for (std::size_t i = 0; i + v.size < data.size(); i += v.size) {
    v = subscript(data, i, v.size);  // simd::simd(span) to be proposed
    // ...
  }
}
\end{lstlisting}


\subsection{Clean up math function overloads}
The wording that produces \code{simd} overloads misses a few cases and leaves room for ambiguity.
There is also no explicit mention of integral overloads that are supported in \code{<cmath>} (e.g. \code{std::cos(1)} calling \code{std::cos(double)}).
At the very least, \code{std::abs(simd<\textit{signed-integral}>)} should be specified.

Also, from implementation experience ``undefined behavior'' for domain, pole, or range error is unnecessary.
It could either be an unspecified result or even match the expected result of the function according to Annex F in the C standard.
The latter could also be only a recommendation, i.e. QoI.

This needs more work and is not reflected in the wording at this point.


\section{Open questions}

\subsection{Remove support for safe parameter passing over ABI boundaries}
\label{sec:noabihelper}

The feature, that \stdx\simdabi\code{fixed_size<N>} acts as a type for safely passing over ABI boundaries was a request/idea from SG1 and was not part of the original design.
My preferred approach would be that users or compilers solve this problem, and not \code{simd}.
Users could pass data via \code{std::array<T, N>} instead of \stdx\code{fixed_size_simd<\MayBreak{}T, N>}; in some situations this might be less efficient, though.
Alternatively, the \code{simd} object can be wrapped in a \code{struct} with non-trivial copy constructor (at least for the Itanium ABI).

A more general solution would require a language extension.
An implementation could provide attributes for adjusting the calling convention for certain functions or function parameters.
This would make it trivial to request less efficient copying at the place where it is needed without extra performance cost in other places.

Removing the \stdx\simdabi\code{fixed_size<N>} / \std\simdabi\code{abi_stable<N>} ABI would resolve the problem that one of the \code{simd} specializations is not trivially copyable and thus not bit-castable.
Furthermore, no type in the \CC{} standard can \emph{guarantee} compatibility on ABI boundaries (i.e. TUs compiled with different compiler flags), since there can be no normative wording to such an effect.
Thus, the type is less useful in this respect to users than it should be.

Consequently, this is my preferred set of standard ABI tags:
\begin{itemize}
  \item \simdabi\code{native<T>}
  \item \simdabi\code{fixed_size<T, N>}
  \item \simdabi\code{scalar}
\end{itemize}
I.e. compared to the TS, remove \code{compatible<T>} and remove the ABI suggestion for \code{fixed_size<T, N>}.
However, that goes against a decision / discussion in SG1, so I would prefer for (at least) SG1 to weigh in on this issue.

\subsubsection{Suggested Poll}

\wgPoll{Remove provision of \code{simd} type (ABI tag) that \emph{might} help passing \code{simd} objects correctly over ABI boundaries}{&&&&}

\subsection{Casts}\label{sec:question-casts}

See \sect{sec:casts} for a discussion.

\subsubsection{Suggested Polls}

\wgPoll{Allow implicit conversions between \code{simd<T>} and
\code{fixed_size_simd<T, N>} (both directions, \code{N == simd<T>::size()})%
\footnote{
This is a change of the TS status quo.
The paper argues that it is an improvement.
}
}{&&&&}

\wgPoll{Remove named cast functions (\code{to_fixed_size}, \code{to_native})%
\footnote{This is a change of the TS status quo.
The paper argues that it if the above poll passes, the functions are
unnecessary.}
}{&&&&}

\subsection{Integration with ranges}
\code{simd} itself is not a range.
The value of a data-parallel object is not an array of elements but rather needs to be understood as a single opaque value that happens to have means for reading and writing element values.
I.e. \code{simd<int> x = \{\};} does not start the lifetime of \type{int} objects.
The \code{element_reference} for \code{operator[]} is bad enough as is.
Let's not exacerbate the problem by adding iterators to \code{simd}.

Instead, a \code{simd} can be converted into an array (e.g. \lst{lst:simdtoarray}).
Conversely, a \std\code{span} with static extent can be converted into a \std\type{simd}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:simdtoarray,caption={
  \code{simd} to \code{array} conversion
}]
template <class T, class A>
std::array<T, std::simd_size_v<T, A>> to_array(std::simd<T, A> x)
{
  std::array<T, std::simd_size_v<T, A>> r;
  x.copy_to(r.data());
  return r;
}
\end{lstlisting}

I plan to pursue conversions to array and from span with static extent in a follow-up paper.
I believe it is not necessary to resolve this question before merging \code{simd} from the TS.

\subsection{Correct place for \code{simd} in the IS?}

While \code{simd} is certainly very important for numerics and therefore fits into the “Numerics library” clause, it is also more than that.
E.g. \code{simd} can be used for vectorization of text processing.
In principle \code{simd} should be understood similar to fundamental types.
Is the “General utilities library” clause a better place?
Or rename “Concurrency support library” to “Parallelism and concurrency support library” and put it there?
Alternatively, add a new library clause?

The author is seeking feedback before making a recommendation.

\section{Wording}

\input{wording2}

\end{document}
% vim: sw=2 sts=2 ai et tw=0
