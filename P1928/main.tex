\newcommand\wgTitle{Merge data-parallel types from the Parallelism TS 2}
\newcommand\wgName{Matthias Kretz <m.kretz@gsi.de>}
\newcommand\wgDocumentNumber{D1928R2}
\newcommand\wgGroup{SG1, LEWG}
\newcommand\wgTarget{\CC{}26}
%\newcommand\wgAcknowledgements{ }

\usepackage{mymacros}
\usepackage{wg21}
\setcounter{tocdepth}{2} % show sections and subsections in TOC
\hypersetup{bookmarksdepth=5}
\usepackage{changelog}
\usepackage{underscore}
\usepackage{comment}

\addbibresource{extra.bib}

\newcommand\simd[1][]{\type{simd#1}\xspace}
\newcommand\simdT{\type{simd<T>}\xspace}
\newcommand\valuetype{\type{value\_type}\xspace}
\newcommand\referencetype{\type{reference}\xspace}
\newcommand\whereexpression{\type{where\_expression}\xspace}
\newcommand\simdcast{\code{simd\_cast}\xspace}
\newcommand\mask[1][]{\type{simd\_mask#1}\xspace}
\newcommand\maskT{\type{simd\_mask<T>}\xspace}
\newcommand\fixedsizeN{\type{simd\_abi::fixed\_size<N>}\xspace}
\newcommand\fixedsizescoped{\type{simd\_abi::fixed\_size}\xspace}
\newcommand\fixedsize{\type{fixed\_size}\xspace}
\newcommand\wglink[1]{\href{https://wg21.link/#1}{#1}}
\DeclareRobustCommand\simdabi{\code{simd\_abi\MayBreak::\MayBreak}}

\renewcommand{\lst}[1]{Listing~\ref{#1}}
\renewcommand{\sect}[1]{Section~\ref{#1}}
\renewcommand{\ttref}[1]{Tony~Table~\ref{#1}}

\begin{document}
\selectlanguage{american}
\begin{wgTitlepage}
  After the Parallelism TS 2 was published in 2018, data-parallel types
  (\simdT) have been implemented and used.
  Now there is sufficient feedback to improve and merge Section 9 of the
  Parallelism TS 2 into the IS working draft.
\end{wgTitlepage}

\pagestyle{scrheadings}

\input{changelog}
\input{strawpolls}

\section{Introduction}
\cite{P0214R9} introduced \simdT and related types and functions into the Parallelism TS 2 Section 9.
The TS was published in 2018.
An incomplete and non-conforming (because P0214 evolved) implementation existed for the whole time P0214 progressed through the committee.
Shortly after the GCC 9 release, a complete implementation of Section 9 of the TS was made available.
Since GCC 11 a complete \code{simd} implementation of the TS is part of its standard library.

In the meantime the TS feedback progressed to a point where a merge should happen ASAP.
This paper proposes to merge only the feature-set that is present in the Parallelism TS 2.
(Note: The first revision of this paper did not propose a merge.)
If, due to feedback, any of these features require a change, then this paper (P1928) is the intended vehicle.
If a new feature is basically an addition to the wording proposed here, then it will progress in its own paper.

\subsection{Related papers}
\begin{description}
  \item[\wglink{P0350}] Before publication of the TS, SG1 approved \cite{P0350R0} which did not progress in time in LEWG to make it into the TS.
    \wglink{P0350} is moving forward independently.

  \item[\wglink{P0918}] After publication of the TS, SG1 approved \cite{P0918R2} which adds \code{shuffle}, \code{interleave}, \code{sum_to}, \code{multiply_sum_to}, and \code{saturated_simd_cast}.
    \wglink{P0918} will move forward independently.

  \item[\wglink{P1068}] R3 of the paper removed discussion/proposal of a \code{simd} based API because it was targeting \CC{}23 with the understanding of \code{simd} not being ready for \CC{}23.
    This is unfortunate as the presence of \code{simd} in the IS might lead to a considerably different assessment of the iterator/range-based API proposed in P1068.

  \item[\wglink{P0917}] The ability to write code that is generic wrt. arithmetic types and \code{simd} types is considered to be of high value (TS feedback).
    Conditional expressions via the \code{where} function were not all too well received.
    Conditional expressions via the conditional operator would provide a solution deemed perfect by those giving feedback (myself included).

  \item[draft on non-member {operator[]}] TODO

  \item[\wglink{P2600}] The fix for ADL is important to ensure the above two papers do not break existing code.

  \item[\wglink{P0543}] The paper proposing functions for saturation arithmetic expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P0553}] The bit operations that are part of \CC{}20 expects \code{simd} overloads as soon as \code{simd} is merged to the IS.

  \item[\wglink{P2638}] Intel’s response to \wglink{P1915R0} for \code{std::simd}

  \item[\wglink{P2663}] \code{std::simd<std::complex<T>>}.

  \item[\wglink{P2664}] Permutations for \code{simd}.

\end{description}
The papers \wglink{P0350}, \wglink{P0918}, \wglink{P2663}, \wglink{P2664}, and
the \code{simd}-based \wglink{P1068} fork currently have no shipping vehicle
and are basically blocked on this paper.

\section{Changes after TS feedback}\label{sec:changes}
\cite{P1915R0} (Expected Feedback from \code{simd} in the Parallelism TS 2) was published in 2019, asking for feedback to the TS.
I received feedback on the TS via the GitHub issue tracker, e-mails, and personal conversations.
There is also a lot of valuable feedback published in \wglink{P2638} ``Intel’s response to \wglink{P1915R0} for \code{std::simd}''.
This paper captures the major change requests but should still be considered a work-in-progress.

\subsection{improve ABI tags}
I received consistent feedback that \simdabi\code{compatible<T>} is the wrong default and it should rather be \simdabi\code{native<T>} instead.
All my tutorial material instructed users to use \stdx\code{native_simd<T>}.
There really is little use for \simdabi\code{compatible<T>}.
The preferred approach should be the use of \simdabi\code{native<T>} together with compiler flags that limit the available registers and instructions to whatever the user deems “compatible”.
Consequently, there is no reason to keep \simdabi\code{compatible<T>} in its current form.

Another common question was about a “fixed size” ABI tag, similar to \stdx\simdabi\code{fixed_size<N>} but without the ABI compatibility cost.%
\footnote{Implementations of the TS are encouraged to make passing \code{fixed_size} objects ABI compatible between different hardware generations and/or even different architectures.}
Basically, the ABI footgun should be as dangerous as \stdx\simdabi\code{native<T>}.
The answer to that FAQ is to use \stdx\simdabi\code{deduce_t<T, N>} as ABI tag.
This will provide you with a high-performance footgun, if supported, but might also fall back to \stdx\simdabi\code{fixed_size<N>}.
With \stdx\simdabi\code{deduce_t<T, N>} turning out to be used potentially more often than \stdx\simdabi\code{fixed_size<N>} the aliases and names should be revisited.
My proposal:

\begin{description}
  \item[\code{A0 = \simdabi native<T>}] \emph{(no change from the TS semantics)}\\
    \code{simd<T, A0>} abstracts a SIMD register (or similar) with highest performance on the target system (typically widest available register, but that's a QoI choice).
    Consequently, the number of elements is chosen by the implementation and may differ for different \code{T} and different compiler flags.
    \simdabi\code{native<T>} is an alias for an unspecified type.
    \simdabi\code{native<T>} can be an alias for \simdabi\code{scalar}.
    If \code{sizeof(simd<T, A0>)} or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1 differ from the same expressions in TU2, then the types \code{A0} in TU1 and TU2 have a different name.

  \item[\code{A1 = \simdabi fixed_size<T, N>}] \emph{(different to the TS semantics)}\\
    \code{simd<T, A1>} abstracts one or more registers storing \code{N} values.
    The actual hardware resources might store more values; but instructions are generated to make it appear as if there are exactly \code{N} values stored and manipulated.

    Parameter passing may be ABI incompatible between different TUs when compiled with different compiler flags.
    Therefore, if \code{sizeof(simd<T, A0>)}%
    \footnote{\code{A0} is not a typo; this depends on \simdabi\code{native<T>}}
    or \code{alignof(\MayBreak{}simd\MayBreak{}<\MayBreak{}T, A0>)} in TU1
    differ from the same expressions in TU2, then the types \code{A1} in TU1
    and TU2 have a different name.
    This new requirement (wrt. the TS) is the reason for the additional
    \code{T} parameter.
    This allows an implementation to define the \code{fixed_size} alias as e.g.
    \lstinline@template <typename T, @
    \lstinline@int N> @
    \lstinline@using fixed_size @
    \lstinline@= _Fixed<N, native<T>>;@.
    \code{A1} and \code{A0} are always different types, i.e. even if \code{simd_size_v<T, A0> == N}.

    A major difference to \stdx\simdabi\code{fixed_size<N>} in the TS is about \code{simd_mask}.
    In order to support ABI stability the \code{simd_mask} implementation must choose one form of storage for all possible targets:
    \begin{itemize}
      \item full SIMD registers with all bits set to 1 or 0 per corresponding element
      \item bitmasks
      \item an array of \code{bool} or similar
    \end{itemize}
    The new intent for the \code{fixed_size<T, N>} ABI tag would be to allow \code{simd_mask<T, A1>} to use either choice depending only on compiler flags.

  \item[\code{A2 = \simdabi scalar}]\ \\
    No change.
\end{description}

At this point the \simdabi\code{deduce} facility seems to be obsolete.
However, it is still a useful tool for implementing the \code{rebind_simd} and \code{resize_simd} traits.
Without more compelling reason for removal, it should be merged as is.
%In theory, its ability to take an optional pack of ABI tags into account for its decision would be lost when removing \simdabi\code{deduce}.
%However, I have not heard of any users who want to use this feature.
%My recommendation is removal.%
%\footnote{For reference: my implementation simply ignores the pack of ABI tags given to \simdabi\code{deduce}.}

\subsubsection{Naming discussion}

For context on naming, consider the use-cases that the ABI tags serve:

\begin{description}
  \item[\simdabi\code{native<T>}] The equivalent to \code{T}: a direct abstraction of available hardware resources in terms of registers and instructions.

  \item[\simdabi\code{fixed_size<T, N>}] Higher abstraction level than \code{native<T>}: the user/algorithm dictates the number of elements to be processed in parallel.
    The objects might not be direct mappings to hardware resources, but they use the best that is available on the given target system.

  \item[\simdabi\code{scalar}] The actual type of \code{native<T>} if the target hardware has no support for parallel processing of elements of \code{T}.%
    \footnote{A typical example is \simdabi\code{native<long double>}.}
    In addition, \code{simd<T, simd_abi::scalar>} can be a useful debugging tool.
\end{description}

For reference, the name \code{fixed_size} is my preference over the following alternatives:
\begin{itemize}
  \item \code{simd_abi::fixed_native<N>} with \code{simd} alias \code{fixed_native_simd<T, N>}
  \item \code{simd_abi::fixed<N>} with \code{simd} alias \code{fixed_simd<T, N>}
  \item \code{simd_abi::sized<N>} with \code{simd} alias \code{sized_simd<T, N>}
\end{itemize}

\subsection{Simplify/generalize casts}\label{sec:casts}

The change to the ABI tags requires a reconsideration of cast functions and
implicit and explicit casts between data-parallel types of different ABI tags.
This is in addition to TS feedback on casts being too strict or cumbersome to use.

\subsubsection{More (explicit) converting constructors}

The TS allows implicit casts between \code{fixed_size<N>} types that only
differ in element type and where the values are preserved (“every possible
value of \code{U} can be represented with type \code{value_type}”).

However, from experience with the TS, it is better to also enable implicit
conversions between any \code{simd} specializations with equal element count,
even if such a conversion might be non-portable between targets with different
native SIMD widths.
The expectation is, that users set up their types according to a pattern
similar to \lst{lst:simdtypespattern}.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:simdtypespattern,caption={
  Recommended setup of \code{simd} types
}]
using  floatv = std::simd<float>;
using doublev = std::rebind_simd_t<double, floatv>;
using  int32v = std::rebind_simd_t<std:: int32_t, floatv>;
using uint32v = std::rebind_simd_t<std::uint32_t, floatv>;
using  int16v = std::rebind_simd_t<std:: int16_t, floatv>;
using uint16v = std::rebind_simd_t<std::uint16_t, floatv>;
// ...
\end{lstlisting}
Thus, users will work with a set of types that have equal number of elements by
construction.
Some of the types may use the \code{fixed_size} ABI tag and some may use an
extended ABI tag.
This detail should not stop the user from being able to cast between a
compiler-flag dependent subset of these types.

Besides a constraint on the number of elements being equal, the converting
constructor should be conditionally \code{explicit}:
Implicit casts are only allowed if the element type conversion is
value-preserving (same wording as in the TS).

This resolves major inconveniences when working with mixed-precision
operations (cf. \ttref{tt:better with conv ctors}).
\begin{tonytable}{Improved generic code after adding converting constructors}\label{tt:better with conv ctors}
  \begin{lstlisting}
namespace stdx = std::experimental;

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              stdx::is_simd_v<T>,
              stdx::rebind_simd_t<int, T>, int>;
  I c;
  if constexpr (stdx::is_simd_v<T>) {
    c = stdx::static_simd_cast<I>(a) + b;
  } else {
    c = static_cast<int>(a) + b;
  }
  g(c);
}
  \end{lstlisting}
  &
  \begin{lstlisting}
// assuming simd in namespace std

template <class T> void f(T a, int b)
{
  using I = std::conditional_t<
              std::is_simd_v<T>,
              std::rebind_simd_t<int, T>, int>;
  I c = static_cast<I>(a) + b;





  g(c);
}
  \end{lstlisting}
\end{tonytable}%
Type conversions for \code{simd} are still less error-prone than builtin types,
because conversions that might lose information require an explicit cast.
Also, unintended widening of the SIMD register size can happen, but typically
leads to the need for an explicit cast in the complete statement (cf.
\lst{lst:mixedprecision}).

\begin{lstlisting}[numbers=left,float={hbtp},label=lst:mixedprecision,caption={
  Mixed precision code using the types from \lst{lst:simdtypespattern}, ensuring equal element count
}]
void f(int32v a, doublev b, floatv c)
{
  doublev x = a * b + c; // OK: implicit (value-preserving) conversion from int and float
    // to double. Requires twice the register space, but there's no way around it and the
    // result type requires it anyway.
  int32v y = a * b; // ERROR: implicit conversion from double to int not value-preserving
  int32v z1 = static_cast<int32v>(a * b); // OK: cast hints at implicit register widening
  int32v z2 = a * static_cast<int32v>(b); // OK
}
\end{lstlisting}

\subsubsection{Remove named cast functions}

From the cast functions \stdx\code{to_fixed_size}, \stdx\code{to_native}, and
\stdx\code{to_compatible} only the conversions from \simdabi\code{fixed_size<T,
N>} to \simdabi\code{native<T>} and back may still benefit from a named cast
function.
Most importantly, the conversion from \code{native} to its \code{fixed_size}
counterpart benefits from a cast expression that does not require spelling out
the destination type.
However, since converting constructors are provided by the standard library, it
is simple for users to define their own \code{to_fixed_size} function if they
want one (e.g.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:userdefined-to-fixed-size,caption={
  Example of a user-defined \code{to_fixed_size} implementation if explicit casts are provided
}]
template <typename T>
constexpr std::fixed_size_simd<T, std::simd_size_v<T>> to_fixed_size(std::simd<T> x)
{
  return x;
}
\end{lstlisting}
\lst{lst:userdefined-to-fixed-size}).
The reverse cast can trivially be spelled out as \code{static_cast<simd<T>>(y)}
in program code.
The only motivation for adding a \code{to_native} function would be the
provision of a counterpart for the \code{to_fixed_size} cast function.

Besides the functions only implementing trivial implicit casts, there is little
to no need for these functions.
The named cast functions are therefore removed altogether.

\subsubsection{Remove \code{simd_cast} and \code{static_simd_cast}}
There are two cast function templates in the TS: \code{simd_cast} and
\code{static_simd_cast}.
The former is equivalent to the latter except that only value-preserving
conversions are allowed.
The template parameter can either be a \code{simd} specialization or a
vectorizable type \code{T}.
In the latter case, the cast function determines the return type as
\code{fixed_size_simd<T, input.size()>}.

Since we allow all conversions covered by \stdx\code{simd_cast} and
\stdx\code{static_simd_cast} via \std\code{simd} constructors, the cast
functions can be removed altogether.
The lost feature (cast via element type) can be replaced using
\code{rebind_simd} as shown in \ttref{tt:tsvsp1928casts}.
\begin{tonytable}{Casting without specifying the target ABI tag}\label{tt:tsvsp1928casts}
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = stdx::static_simd_cast<double>(x);
  // ...
}
  \end{lstlisting}
  &
  \begin{lstlisting}
template <typename V>
void f(V x)
{
  const auto y = std::rebind_simd_t<double, V>(x);
  // ...
}
  \end{lstlisting}
\end{tonytable}%

\subsubsection{mask casts}
\code{simd_mask} casts should work when \code{simd} casts work.
I.e. if \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
then \code{simd_mask<T0, A0>} is implicitly convertible to \code{simd_mask<T1,
A1>}.
The reverse (if \code{simd_mask} is convertible then \code{simd} is
convertible) does not have to be true.
Specifically, the TS allows all \code{fixed_size<N>} mask to be
interconvertible, irrespective of the element type.
For the IS merge, the proposal is to make this more consistent with \code{simd}
while also preserving most of the convenience:
Allow implicit conversions if the \code{sizeof} the element types are equal,
otherwise the conversion must be explicit.

Conversions with different element count are not possible via a constructor
(consistent with \code{simd}).
This would require a different function, such as the \code{resize<N>(simd)}
function proposed by \textcite{P2638R0}.

\subsubsection{Complete casts for \code{simd_mask}}
The \code{simd_cast} and \code{static_simd_cast} overloads for \code{simd_mask} were forgotten for the TS.
Without those casts (and no casts via constructors) mixing different arithmetic types is painful.
There is no motivation for forbidding casts on \code{simd_mask}.

The proposed changes for casts solve this issue.

\subsubsection{Summary of casts}

\begin{enumerate}
  \item \code{simd<T0, A0>} is convertible to \code{simd<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd<T0, A0>} is implicitly convertible to \code{simd<T1, A1>}
    if, additionally, the conversion \code{T0} to \code{T1} is
    value-preserving.

  \item \code{simd_mask<T0, A0>} is convertible to \code{simd_mask<T1, A1>} if
    \code{simd_size_v<T0, A0> == simd_size_v<T1, A1>}.

  \item \code{simd_mask<T0, A0>} is implicitly convertible to
    \code{simd_mask<T1, A1>} if, additionally, \code{sizeof(T0) ==
    sizeof(T1)}.

  \item \code{simd<T0, A0>} can be \code{bit_cast}ed to \code{simd<T1, A1>} if
    \code{sizeof(simd<T0, A0>) == sizeof(simd<T1, A1>)}.

  \item \code{simd_mask<T0, A0>} can be \code{bit_cast}ed to \code{simd_mask<T1, A1>} if
    \code{sizeof(simd_mask<T0, A0>) == sizeof(simd_mask<T1, A1>)}.
\end{enumerate}

\subsection{Add \code{simd_mask} generator constructor}
The \code{simd} generator constructor is very useful for initializing objects
from scalars in a portable (i.e. different \code{simd::size()}) fashion.
The need for a similar constructor for \code{simd_mask} is less frequent, but,
even if only for consistency, there should be one.
Besides consistency, it is also useful, of course.
Consider a predicate function that is given without \code{simd} interface (e.g. from a library).
How do you construct a \code{simd_mask} from it?
With a generator constructor it is easy:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  const simd_mask<T> k([&](auto i) { return p(x[i]); });
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
Without the generator constructor one has to write e.g.:
\medskip\begin{lstlisting}[style=Vc]
simd<T> f(simd<T> x, Predicate p) {
  simd_mask<T> k;
  for (size_t i = 0; i < simd<T>::size(); ++i) {
    k[i] = p(x[i]);
  }
  where(k, x) = 0;
  return x;
}
\end{lstlisting}
The latter solution makes it hard to initialize the \code{simd_mask} as \code{const}, is more verbose, is harder to optimize, and cannot use the sequencing properties the generator constructor allows.

Therefore add:
\begin{wgText}
\begin{itemdecl}
template<class G> simd_mask(G&& gen) noexcept;
\end{itemdecl}
\end{wgText}

\subsection{\code{element_reference} is overspecified}
\code{element_reference} is spelled out in a lot of detail.
It may be better to define its requirements in a table instead.

This change is not reflected in the wording, pending encouragement from WG21 (mostly LWG).

\subsection{Default load/store flags to \code{element_aligned}}

Consider:
\medskip\begin{lstlisting}[style=Vc,numbers=left]
std::simd<float> v(addr, std::vector_aligned); @\label{lstline:vector_aligned}@
v.copy_from(addr + 1, std::element_aligned); @\label{lstline:load element_aligned}@
v.copy_to(dest, std::element_aligned); @\label{lstline:store element_aligned}@
\end{lstlisting}
Line~\ref{lstline:vector_aligned} supplies an optimization hint to the load operation.
Line~\ref{lstline:load element_aligned} says what really?
“Please don't crash.
I know this is not a vector aligned access\footnote{Of course, vector aligned is equivalent to element aligned if \code{simd<float>::size() == 1}}.”
Line~\ref{lstline:store element_aligned} says:
“I don't know whether it's vector aligned or not.
Compiler, if you know more, please optimize, otherwise just don't make it crash.”
(To clarify, the difference between lines~\ref{lstline:load element_aligned} and~\ref{lstline:store element_aligned} is what line~\ref{lstline:vector_aligned} says about the alignment of \code{addr}.)
In both cases of \code{element_aligned} access, the developer requested a behavior we take as given in all other situations.
Why does the TS force to spell it out in this case?

Since \CC{}20, we also have another option:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(std::assume_aligned<std::memory_alignment_v<std::simd<float>>>(addr)); @\label{lstline:assume_aligned}@
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}
This seems to compose well, except that line \ref{lstline:assume_aligned} is rather long for a common pattern in this interface.
Also, this removes implementation freedom because the library cannot statically determine the alignment properties of the pointer.

Consequently, as a minimal improvement to the TS keep the load/store flags as
is, but default them to \code{element_aligned}.
I.e.:
\medskip\begin{lstlisting}[numbers=left]
std::simd<float> v(addr, std::vector_aligned);
v.copy_from(addr + 1);
v.copy_to(dest);
\end{lstlisting}

\subsection{\code{constexpr} everything}
The libstdc++ implementation implements the complete TS API as \code{constexpr} as an optional extension.
This is useful (e.g. for computing constants) and not a significant implementation burden.
Users (as well as \textcite{P2638R0}) have called for \code{constexpr}.
The merge consequently adds \code{constexpr} to all functions.

\subsection{Specify \code{simd::size} as \code{integral_constant}}
The TS specifies \code{simd::size} as a \code{static constexpr} function returning the number of elements of the \code{simd} specialization.
Instead of a function, this paper uses a static data member of type \code{std::integral_constant<std::size_t, N>}, which is both convertible to \code{std::size_t} and callable.
The upside of using a static data member is that it can be used as function parameter without conversion to integer and thus easily pass the size into a function as constant expression.
See \lst{lst:sizeparam} for an example.
\begin{lstlisting}[numbers=left,float={hbtp},label=lst:sizeparam,caption={
    Example: Pass \code{simd::size} as ``constant expression function argument''
}]
template <std::ranges::contiguous_range R, std::size_t Size>
std::span<const std::ranges::range_value_t<R>, Size>
auto subscript(const R& r, std::size_t first, std::integral_constant<std::size_t, Size>) {
  return std::span<const std::ranges::range_value_t<R>, Size>(
    std::ranges::data(r) + first, Size());
}

void g(std::vector<float> data) {
  std::simd<float> v;
  for (std::size_t i = 0; i + v.size < data.size(); i += v.size) {
    v = subscript(data, i, v.size);  // simd::simd(span) to be proposed
    // ...
  }
}
\end{lstlisting}


\subsection{Clean up math function overloads}
The wording that produces \code{simd} overloads misses a few cases and leaves room for ambiguity.
There is also no explicit mention of integral overloads that are supported in \code{<cmath>} (e.g. \code{std::cos(1)} calling \code{std::cos(double)}).
At the very least, \code{std::abs(simd<\textit{signed-integral}>)} should be specified.

Also, from implementation experience ``undefined behavior'' for domain, pole, or range error is unnecessary.
It could either be an unspecified result or even match the expected result of the function according to Annex F in the C standard.
The latter could also be only a recommendation, i.e. QoI.

This needs more work and is not reflected in the wording at this point.


\section{Open questions}

\subsection{Integration with ranges}
\code{simd} itself is not a container.
The value of a data-parallel object is not an array of elements but rather needs to be understood as a single opaque value that happens to have means for reading and writing element values.
I.e. \code{simd<int> x = \{\};} does not start the lifetime of \type{int} objects.
This implies that \code{simd} cannot model a contiguous range but only a random-access range.
\code{simd} can trivially model \code{input_range}.
However, in order to model \code{output_range}, the iterator of every non-const \code{simd} would have to return an \code{element_reference} on dereference.
Without the ability of \code{element_reference} to decay to the element type (similar to how arrays decay to pointers on deduction), I would prefer to simply make \code{simd} model only \code{input_range}.

I plan to pursue adding iterators and conversions to array and from random-access ranges, specifically \code{span} with static extent, in a follow-up paper.
I believe it is not necessary to resolve this question before merging \code{simd} from the TS.

\subsection{Correct place for \code{simd} in the IS?}

While \code{simd} is certainly very important for numerics and therefore fits into the “Numerics library” clause, it is also more than that.
E.g. \code{simd} can be used for vectorization of text processing.
In principle \code{simd} should be understood similar to fundamental types.
Is the “General utilities library” clause a better place?
Or rename “Concurrency support library” to “Parallelism and concurrency support library” and put it there?
Alternatively, add a new library clause?

I am seeking feedback before making a recommendation.

\section{Wording}

\input{wording2}

\end{document}
% vim: sw=2 sts=2 ai et tw=0
