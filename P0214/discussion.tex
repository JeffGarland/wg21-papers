\section{Discussion}

\subsection{Member Types}
The member types may not seem obvious.
Rationales:
\begin{typelist*}
  \item[value_type]
    In the spirit of the \valuetype member of STL containers, this type denotes the \emph{logical} type of the values in the vector.

  \item[register_value_type]
    On some targets it may be beneficial to implement \datapar instantiations of some \type T with a different type \type{register_value_type}, which has higher precision than \type T.
    This is mostly an implementation detail, but can be important to know in some situations, especially whenever \type{native_handle_type} is involved.

    \guidance{A better name might be \type{native_value_type}.}

  \item[native_handle_type]
    The type used for enabling access to an implementation-defined member object (via the \code{native_handle()} function).

  \item[reference]
    Used as the return type of the non-const scalar subscript operator.

  \item[mask_type]
    The natural \mask type for this \datapar instantiation.
    This type is used as return type of compares and write-mask on assignments.

  \item[datapar_type]
    The natural \datapar type for this \mask instantiation.

  \item[size_type]
    Standard member type used for \code{size()} and \code{operator[]}.

  \item[abi_type]
    The \type{Abi} template parameter to \datapar.

\end{typelist*}

\subsection{Default Construction}
The default constructors of \datapar and \mask zero-initialize the object.
This is important for compatibility with \code{\type T()}, which zero-initializes fundamental types.
There may be a concern that unnecessary initialization could lead to unnecessary instructions.
I consider this a QoI issue.
Implementations are certainly able to recognize unnecessary initializations in many cases.

\subsection{Conversions}
The \datapar conversion constructor only allows implicit conversion from \datapar template instantiations with the same \type{Abi} type and compatible \valuetype.
Discussion in SG1 showed clear preference for only allowing implicit conversion between integral types that only differ in signedness.
All other conversions could be implemented via an explicit conversion constructor.
The alternative (preferred) is to use \simdcast consistently for all other conversions.

\subsection{Broadcast Constructor}
The broadcast constructor is not declared as \code{explicit} to ease the use of scalar prvalues in expressions involving data-parallel operations.
The operations where such a conversion should not be implicit consequently need to use SFINAE / concepts to inhibit the conversion.

\subsection{Aliasing of Subscript Operators}
The subscript operators return an rvalue.
The const overload returns a copy of the element.
The non-const overload returns a smart reference.
This reference behaves mostly like an lvalue reference, but without the requirement to implement assignment via type punning.
At this point the specification of the smart reference is very conservative / restrictive:
The reference type is neither copyable nor movable.
The intention is to avoid users to program like the operator returned an lvalue reference.
The return type is significantly larger than an lvalue reference and harder to optimize when passed around.
The restriction thus forces users to do element modification directly on the \datapar / \mask objects.

Guidance from SG1 at JAX 2016:\\
\wgPoll{Should subscript operator return an lvalue reference?}{0  & 6 & 10 & 2 & 1}

\wgPoll{Should subscript operator return a “smart reference”?}{1  & 7 & 10 & 0 & 0}

\subsection{Parameters of Binary and Compare Operators}
It is easier to implement and possibly easier to specify these operators if the signature is specified as:
\begin{itemdecl}
template <class T, class U>
datapar_return_type<T, U> operator+(const T &, const U &);
\end{itemdecl}
The motivation for using a variant where at least one function parameter is constrained to the \datapar class template is compilation speed.
The compiler can drop the operator from the overload resolution set quicker.
With concepts it might be worthwhile to revisit this decision.

\subsection{Compound Assignment}
The semantics of compound assignment would allow less strict implicit conversion rules.
Consider \code{datapar<int>() *= double()}: the corresponding multiplication operator would not compile because the implicit conversion to \datapar[<float>] is non-portable.
Compound assignment, on the other hand, implies an implicit conversion back to the type of the expression on the left of the assignment operator.
Thus, it is possible to define compound operators that execute the operation correctly on the promoted type without sacrificing portability.
There are two arguments for not relaxing the rules for compound assignment, though:
\begin{enumerate}
  \item Consistency: The conversion of an expression with compound assignment to a binary operator suddenly would not compile anymore.
  \item The implicit conversion in the \code{int * double} case could be expensive and unintended.
    This is already a problem for builtin types where many developers multiply \float variables with \double prvalues.
\end{enumerate}

\subsection{Return Type of Masked Assignment Operators}
The assignment operators of the type returned by \code{where(mask, datapar)} could return one of:
\begin{itemize}
  \item A reference to the \datapar object that was modified.
  \item A temporary \datapar object that only contains the elements where the \mask is \true.
  \item The object returned from the \code{where} function.
  \item Nothing (\ie \void).
\end{itemize}
My first choice was a reference to the modified \datapar object.
However, then the statement \code{(where(x < 0, x) *= -1) += 2} may be surprising: it adds \code 2 to all vector entries, independent of the mask.
Likewise, \code{y += (where(x < 0, x) *= -1)} has a possibly confusing interpretation because of the \mask in the middle of the expression.

Consider that write-masked assignment is used as a replacement for \code{if}-statements.
Using \void as return type therefore is a more fitting choice because \code{if}-statements have no return value.
By declaring the return type as \void the above expressions become ill-formed, which seems to be the best solution for guiding users to write maintainable code and express intent clearly.

\subsection{Fundamental SIMD Type or Not?}
\subsubsection{The Issue}
There was substantial discussion on the reflectors and SG1 meetings over the question whether \CC{} should define a fundamental, native SIMD type (let us call it \type{fundamental<T>}) and additionally a generic data-parallel type which supports an arbitrary number of elements (call it \type{arbitrary<T, N>}).
The alternative to defining both types is to only define \type{arbitrary<T, N = default_size<T>>}, since it encompasses the \type{fundamental<T>} type.

With regard to this proposal this second approach would add a third template parameter to \datapar and \mask as shown in \lst{datapar N}.
\begin{lstlisting}[style=Vc,numbers=left,float,label=lst:datapar N,caption={
  Possible declaration of the class template parameters of a \datapar class with arbitrary width.
}]
template <class T, size_t N = datapar_size_v<T, datapar_abi::compatible>,
          class Abi = datapar_abi::compatible>
class datapar;
\end{lstlisting}

\subsubsection{Standpoints}
The controversy is about how the flexibility of a type with arbitrary \code N is presented to the users.
Is there a (clear) distinction between a “fundamental” type with target-dependent (i.e. fixed) \code N and a higher-level abstraction with arbitrary \code N which can potentially compile to inefficient machine code.
Or should the \CC{} standard only define \type{arbitrary} and set it to a default \code N value that corresponds to the target-dependent \code N.
Thus, the default \code N, of \type{arbitrary} would correspond to \type{fundamental}.

It is interesting to note that \type{arbitrary<T, 1>} is the class variant of \type T.
Consequently, if we say there is no need for a \type{fundamental} type then we could argue for the deprecation of the builtin arithmetic types, in favor of \type{arbitrary<T, 1>}. \wgNote{This is an academic discussion, of course.}

The author has implemented a library where a clear distinction is made between \type{fundamental<T, Abi>} and \type{arbitrary<T, N>}.
The documentation and all teaching material says that the user should program with \type{fundamental}.
The \type{arbitrary} type should be used in special circumstances, or wherever \type{fundamental} works with the \type{arbitrary} type in its interfaces (e.g. for gather \& scatter or the \code{ldexp} \& \code{frexp} functions).

\subsubsection{Issues}
The definition of two separate class templates can alleviate some source compatibility issues resulting from different \code N on different target systems.
Consider the simplest example of a multiplication of an \intt vector with a \float vector:
\smallskip\begin{lstlisting}[style=Vc]
arbitrary<float>() * arbitrary<int>();  // compiles for some targets, fails for others
fundamental<float>() * fundamental<int>();  // never compiles, requires explicit cast
\end{lstlisting}
The \datapar[<T>] operators are specified in such a way that source compatibility is ensured.
For a type with user definable \code N, the binary operators should work slightly different with regard to implicit conversions.
Most importantly, \type{arbitrary<T, N>} solves the issue of portable code containing mixed integral and floating-point values.
A user would typically create aliases such as:
\smallskip\begin{lstlisting}[style=Vc]
using floatvec = datapar<float>;
using intvec = arbitrary<int, floatvec::size()>;
using doublevec = arbitrary<int, floatvec::size()>;
\end{lstlisting}
Objects of types \type{floatvec}, \type{intvec}, and \type{doublevec} will work together independent of the target system.

Obviously, these type aliases are basically the same if the \code N parameter of \type{arbitrary} has a default value:
\smallskip\begin{lstlisting}[style=Vc]
using floatvec = arbitrary<float>;
using intvec = arbitrary<int, floatvec::size()>;
using doublevec = arbitrary<int, floatvec::size()>;
\end{lstlisting}
The ability to create these aliases is not the issue.
Seeing the need for using such a pattern is the issue.
Typically, a developer will think no more of it if his code compiles on his machine.
If \code{arbitrary<float>() * arbitrary<int>()} just happens to compile (which is likely) then this is the code that will get checked in to the repository.
Note that with the existence of the \type{fundamental} class template, the \code N parameter of the \type{arbitrary} class would not have a default value and thus force the user to think a second longer about portability.

\subsubsection{Progress}
SG1 Guidance at JAX 2016:\\
\wgPoll{Specify datapar width using ABI tag, with a special template tag for fixed size.}{3 & 7 & 0 & 0 & 1}
\wgPoll{Specify datapar width using <T, N, abi>, where abi is not specified by the user.}{1 & 2 & 5 & 2 & 1}

At the Jacksonville meeting, SG1 decided to continue with the \datapar[<T, Abi>] class template, with the addition of a new Abi type that denotes a user-requested number of elements in the vector (\fixedsizeN).
This has the following implications:
\begin{itemize}
  \item There is only one class template with a common interface for \textit{fundamental} and \textit{arbitrary} (\fixedsize) vector types.
  \item There are slight differences in the conversion semantics for \datapar types with the \fixedsize Abi type.
    This may look like the \code{vector<bool>} mistake all over again.
    I'll argue below why I believe this is not the case.
  \item The \textit{fundamental} class instances could be implemented in such a way that they do not guarantee ABI compatibility on a given architecture where translation units are compiled with different compiler flags (for micro-architectural differences).
  \item The \fixedsize class instances, on the other hand, could be implemented to be the ABI stable types (if an implementation thinks this is an important feature).
    In implementation terms this means that \textit{fundamental} types are allowed to be passed via registers on function calls.
    \fixedsize types can be implemented in such a way that they are only passed via the stack, and thus an implementation only needs to ensure equal alignment and memory representation across TU borders for a given \type T, \code N.
\end{itemize}

The conversion differences between the \textit{fundamental} and \fixedsize class template instances are the main motivation for having a distinction (cf. discussion above).
The differences are chosen such that, in general, \textit{fundamental} types are more restrictive and do not turn into \fixedsize types on any operation that involves no \fixedsize types.
Operations of \fixedsize types allow easier use of mixed precision code as long as no elements need to be dropped / generated (i.e. the number of elements of all involved \datapar objects is equal or a builtin arithmetic type is broadcast).

Examples:

\begin{enumerate}
  \item Mixed \intt--\float operations
\smallskip\begin{lstlisting}[style=Vc]
using floatv = datapar<float>;  // native ABI
using float_sized_abi = datapar_abi::fixed_size<floatv::size()>;
using intv = datapar<int, float_sized_abi>;

auto x = floatv() + intv();/*! \label{lstline:1} */
floatv y = floatv() + intv();/*! \label{lstline:2} */
\end{lstlisting}
    Line \ref{lstline:1} is well-formed:
    It states that $N$ (= \type{floatv}\code{::size()}) float elements are concurrently and component-wise added to $N$ \intt elements.
    Effectively, the operands are converted to \datapar[<\float, \fixedsizeN{}>] and subsequently the type of \code x is the same.
    Since implicit conversion from \datapar[<T, \fixedsizeN{}>] to \datapar[<\type U, \type{Abi}>] is allowed whenever \code{N == \datapar{}<\type U, \type{Abi}>::size()}, the construction of \code y on line \ref{lstline:2} is valid as well.
\end{enumerate}


\subsection{Native Handle}\label{sec:native}
The presence of a \code{native_handle} function for accessing an internal data member such as e.g. a vector builtin or SIMD intrinsic type is seen as an important feature for adoption in the target communities.
Without such a handle the user is constrained to work within the (limited) API defined by the standard.
Many SIMD instruction sets have domain-specific instructions that will not easily be usable (if at all) via the standardized interface.
A user considering whether to use \datapar or a SIMD extension such as vector builtins or SIMD intrinsics might decide against \datapar just for fear of not being able to access all functionality.\footnote{
  Whether that's a reasonable fear is a different discussion.
}

I would be happy to settle on an alternative to exposing an lvalue reference to a data member.
Consider implementation-defined support casting (\code{static_cast}?) between \datapar and non-standard SIMD extension types.
My understanding is that there could not be any normative wording about such a feature.
However, I think it could be useful to add a non-normative note about making \code{static_cast}(?) able to convert between such non-standard extensions and \datapar.

Guidance from SG1 at Oulu 2016:\\
\wgPoll{Keep \code{native_handle} in the wording?}{0 & 6 & 3 & 3 & 0}

\subsection{Load \& Store Flags}\label{sec:flags}
SIMD loads and stores require at least an alignment option.
This is in contrast to implicit loads and stores present in \CC{}, where alignment is always assumed.
Many SIMD instruction sets allow more options, though:
\begin{itemize}
  \item Streaming, non-temporal loads and stores
  \item Software prefetching
\end{itemize}
In the Vc library I have added these as options in the load store flag parameter of the \code{load} and \code{store} functions.
However, non-temporal loads \& stores and prefetching are also useful for the existing builtin types.
I would like guidance on this question: should the general direction be to stick to \emph{only} alignment options for \datapar loads and stores?

The other question is on the default of the load and store flags.
Some argue for setting the default to \code{aligned}, as that's what the user should always aim for and is most efficient.
Others argue for \code{unaligned} since this is safe per default.
The Vc library before version 1.0 used aligned loads and stores per default.
After the guidance from SG1 I changed the default to unaligned loads and stores with the Vc 1.0 release.
Changing the default is probably the worst that could be done, though.\footnote{As I realized too late.}
For Vc 2.0 I will drop the default.

For \datapar I prefer no default:
\begin{itemize}
  \item This makes it obvious that the API has the alignment option.
    Users should not just take the default and think no more of it.
  \item If we decide to keep the load constructor, the alignment parameter (without default) nicely disambiguate the load from the broadcast.
  \item The right default would be application/domain/experience specific.
  \item Users can write their own load/store wrapper functions that implement their chosen default.
\end{itemize}

Guidance from SG1 at Oulu 2016:\\
\wgPoll{Should the interface provide a way to specify a number for over-alignment?}{2 & 6 & 5 & 0 & 0}
\wgPoll{Should loads and stores have a default load/store flag?}{0 & 0 & 7 & 4 & 1}

% vim: tw=0 sw=2 spell
